{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Theory"
      ],
      "metadata": {
        "id": "9FkH777538FA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques 1.What is Simple Linear Regression?\n",
        "Ans.Simple Linear Regression is a statistical method to model the relationship between a dependent variable\n",
        "Y and one independent variable\n",
        "X, using a straight line equation Y = mX+c."
      ],
      "metadata": {
        "id": "pl2zYOuO4DKC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques 2.What are the key assumptions of Simple Linear Regression?\n",
        "Ans.Linearity, independence of errors, homoscedasticity (constant variance of errors), normal distribution of errors, and no significant outliers."
      ],
      "metadata": {
        "id": "mwU0HIGI5s_x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques 3.What does the coefficient m represent in the equation Y=mX+c ?\\\n",
        "Ans.The coefficient m represents the slope of the line‚Äîhow much Y changes for a unit change in X.\n"
      ],
      "metadata": {
        "id": "wMzykS_35zAa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques 4.What does the intercept c represent in the equation Y=mX+c ?\n",
        "Ans. The intercept c is the value of Y when ùëã=0. It sets the starting point of the regression line on the Y-axis."
      ],
      "metadata": {
        "id": "tC-cWzOH52_H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques 5.- How do we calculate the slope m in Simple Linear Regression?\n",
        "Ans. The slope m is calculated using the formula:\n",
        "              m = (y2-y1)/(x2-x1)"
      ],
      "metadata": {
        "id": "16u1uVRq6Kc4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques 6.- What is the purpose of the least squares method in Simple Linear Regression?\n",
        "\n",
        "Ans. It minimizes the sum of the squares of the differences between observed and predicted values, giving the best-fitting line.\n"
      ],
      "metadata": {
        "id": "cKtaqHrW7DsK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques 7.- How is the coefficient of determination (R¬≤) interpreted in Simple Linear Regression?\n",
        "\n",
        "Ans.R¬≤ (coefficient of determination) measures how well the regression line explains the variance in the dependent variable. Ranges from 0 to 1."
      ],
      "metadata": {
        "id": "Dk62bAvB7Nii"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques 8. What is Multiple Linear Regression?\n",
        "Ans.It models the relationship between one dependent variable and two or more independent variables using a linear equation."
      ],
      "metadata": {
        "id": "1G_P_ugn7ag0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques 9.What is the main difference between Simple and Multiple Linear Regression?\n",
        "\n",
        "Ans.Simple uses one independent variable, while multiple uses two or more to predict the dependent variable."
      ],
      "metadata": {
        "id": "y87O84bC7iFG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "  Ques 10.What are the key assumptions of Multiple Linear Regression?\n",
        "\n",
        "  Ans.Linearity, independence, homoscedasticity, normality of residuals, and no multicollinearity among predictors."
      ],
      "metadata": {
        "id": "x9rNYkCb7wP-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques 11. What is heteroscedasticity, and how does it affect the results of a Multiple Linear Regression model?\n",
        "\n",
        "Ans.Heteroscedasticity occurs when the variance of residuals is not constant. It can lead to inefficient estimates and biased statistical tests."
      ],
      "metadata": {
        "id": "WhhqIO4j76xf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques 12.- How can you improve a Multiple Linear Regression model with high multicollinearity?\n",
        "\n",
        "Ans.Use techniques like removing correlated predictors, using Principal Component Analysis (PCA), or applying regularization (Ridge/Lasso)."
      ],
      "metadata": {
        "id": "uAareXCq8D3_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques 13.- What are some common techniques for transforming categorical variables for use in regression models?\n",
        "\n",
        "Ans.Use One-Hot Encoding, Label Encoding, or dummy variables to convert categorical data into numerical form."
      ],
      "metadata": {
        "id": "hdW6PtCv8ZYx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Quea 14.What is the role of interaction terms in Multiple Linear Regression?\n",
        "\n",
        "Ans.They allow the effect of one variable on the dependent variable to depend on the level of another variable, capturing complex relationships."
      ],
      "metadata": {
        "id": "Ro3noZ7m8ku3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques 15.How can the interpretation of intercept differ between Simple and Multiple Linear Regression?\n",
        "\n",
        "Ans.In simple regression, it‚Äôs the value of Y when X = 0. In multiple regression, it's the value of Y when all Xs = 0, often less interpretable."
      ],
      "metadata": {
        "id": "3oLW7pC980Iu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques 16.- What is the significance of the slope in regression analysis, and how does it affect predictions?\n",
        "\n",
        "Ans.It shows the strength and direction of the relationship between each predictor and the dependent variable, influencing predictions directly."
      ],
      "metadata": {
        "id": "gYE13Ifb9DaO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques 17.- How does the intercept in a regression model provide context for the relationship between variables?\n",
        "\n",
        "Ans.The intercept helps establish a baseline value for Y, giving meaning to predictions, especially when inputs are near zero."
      ],
      "metadata": {
        "id": "gCfX3JDB9NK7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques 18.What are the limitations of using R¬≤ as a sole measure of model performance?\n",
        "\n",
        "Ans.It doesn't account for overfitting, doesn‚Äôt show if the model is biased, and doesn‚Äôt indicate the significance of predictors.\n"
      ],
      "metadata": {
        "id": "pxR1eB179XuE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques 19.- How would you interpret a large standard error for a regression coefficient?\n",
        "\n",
        "Ans.It indicates that the estimate is unreliable and varies greatly between samples; the coefficient might not be statistically significant."
      ],
      "metadata": {
        "id": "QjpKKW3r9g-Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques 20.How can heteroscedasticity be identified in residual plots, and why is it important to address it?\n",
        "\n",
        "Ans.Look for a fan or cone shape in residuals vs fitted values. Addressing it is crucial for valid inference and confidence intervals."
      ],
      "metadata": {
        "id": "jjpMdYTm9p5m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques 21.What does it mean if a Multiple Linear Regression model has a high R¬≤ but low adjusted R¬≤?\n",
        "\n",
        "Ans.It suggests that some predictors do not contribute meaningfully, and the model may be overfitting with unnecessary variables."
      ],
      "metadata": {
        "id": "O2zNTsUa9yoV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques 22.- Why is it important to scale variables in Multiple Linear Regression?\n",
        "\n",
        "Ans.Scaling helps ensure all variables contribute equally, especially important when using regularization techniques or comparing coefficients."
      ],
      "metadata": {
        "id": "OlZDzno896hB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques 23.What is polynomial regression?\n",
        "\n",
        "Ans.It's an extension of linear regression where the relationship is modeled as an nth-degree polynomial, capturing non-linear patterns.\n",
        "\n"
      ],
      "metadata": {
        "id": "584_InDU-B6I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques 24. How does polynomial regression differ from linear regression?\n",
        "\n",
        "Ans.Linear regression fits a straight line, while polynomial regression fits curves, using higher-degree terms of the independent variable."
      ],
      "metadata": {
        "id": "3-B3kZE--NDV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques 25.When is polynomial regression used?\n",
        "\n",
        "Ans.When data shows a non-linear trend that a straight line cannot capture, such as curves, peaks, or dips in the data."
      ],
      "metadata": {
        "id": "fdOiltHd-haf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques 26.- What is the general equation for polynomial regression?\n",
        "\n",
        "Ans. Y = b0 + b1X + b2X^2 +...+ bnX^n\n"
      ],
      "metadata": {
        "id": "8xxNGWg2-tPb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques 27.Can polynomial regression be applied to multiple variables?\n",
        "\n",
        "Ans.Yes, it becomes a multivariable polynomial regression, where each variable can have polynomial terms (e.g., X1^2 , X2^3)\n"
      ],
      "metadata": {
        "id": "StUxDhn__a71"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques 28.What are the limitations of polynomial regression?\n",
        "\n",
        "Ans.Can easily overfit, sensitive to outliers, high-degree polynomials can oscillate wildly, and interpretability decreases."
      ],
      "metadata": {
        "id": "UxKhu63J_zMA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques 29. What methods can be used to evaluate model fit when selecting the degree of a polynomial?\n",
        "\n",
        "Ans.Use cross-validation, adjusted R¬≤, AIC/BIC, or validation set performance to choose the optimal polynomial degree."
      ],
      "metadata": {
        "id": "JBo4S0G6_7di"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques 30.Why is visualization important in polynomial regression?\n",
        "\n",
        "Ans.It helps understand if the model captures the pattern well and whether it's overfitting or underfitting the data."
      ],
      "metadata": {
        "id": "ysAf3ba9AEbS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques 31.How is polynomial regression implemented in Python?\n",
        "\n",
        "Ans.Using scikit-learn:\n",
        "\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "poly = PolynomialFeatures(degree=2)\n",
        "X_poly = poly.fit_transform(X)\n",
        "model = LinearRegression().fit(X_poly, y)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9Y3KDpOeARda"
      }
    }
  ]
}